{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv,json,time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import datetime\n",
    "import numpy as np\n",
    "import lxml, html5lib\n",
    "from tqdm import tqdm\n",
    "\n",
    "#install selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from requests import Request, Session\n",
    "import requests_cache, re\n",
    "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
    "import subprocess #to extract from clipboard\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--incognito')\n",
    "options.add_argument('headless')\n",
    "cmc_urls=[]\n",
    "\n",
    "for j in range(1,3):\n",
    "    print(j)\n",
    "    url = \"https://coinmarketcap.com/?page=\"+str(j)\n",
    "\n",
    "    wd = webdriver.Chrome(options=options)\n",
    "    wd.get(url)\n",
    "    soup = bs(wd.page_source, 'lxml')\n",
    "    tables = soup.find_all('table')\n",
    "\n",
    "    rows = soup.find_all(\"tr\")\n",
    "    print(rows)\n",
    "    for i in range(1,len(rows)):#ignore first row which is title, and last row\n",
    "        print(i)\n",
    "        try:\n",
    "            links = rows[i].find(\"a\").get(\"href\") # the first link of each row is the coingecko token url that I want to extract\n",
    "            print(links)\n",
    "        except:\n",
    "            links=None\n",
    "            print(\"fake row\")\n",
    "\n",
    "        if links!=None:\n",
    "            #link = links[0]\n",
    "            cmc_urls.append(links)\n",
    "\n",
    "all_tokens = pd.DataFrame(cmc_urls,columns=[\"cmc_url\"])\n",
    "print(all_tokens[all_tokens.duplicated()])\n",
    "all_tokens.to_csv(\"tokens_cmc_2024.csv\", index=False)\n",
    "\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmc_all = pd.read_csv(\"tokens_cmc_2024.csv\")\n",
    "\n",
    "all_url = cmc_all[\"cmc_url\"].tolist()\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--incognito')\n",
    "options.add_argument('headless')\n",
    "\n",
    "\n",
    "for i in range(2): #len(all_url)\n",
    "    print(i)\n",
    "    url = \"https://coinmarketcap.com\" + all_url[i] + \"historical-data/\"\n",
    "\n",
    "    wd = webdriver.Chrome(options=options)\n",
    "    wd.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    # #click \"calendar\" button\n",
    "    calendar_xpath = '/html/body/div[1]/div[2]/div/div[2]/div/div/div/div[2]/div/div[1]/div/button[1]'\n",
    "    #calendar_class=\"sc-f70bb44c-0.iQEJet.BaseButton_labelWrapper__wzpX7\"\n",
    "    try:\n",
    "        WebDriverWait(wd,10).until(EC.presence_of_element_located((By.XPATH,calendar_xpath)))\n",
    "        #WebDriverWait(wd,10).until(EC.presence_of_element_located((By.CLASS_NAME, calendar_class)))\n",
    "    except:\n",
    "        print(\"Cannot find 'calendar' button!\")\n",
    "\n",
    "\n",
    "    calendar_button = wd.find_element(By.XPATH,calendar_xpath)\n",
    "    #calendar_button = wd.find_element(By.CLASS_NAME, calendar_class)\n",
    "    wd.execute_script(\"arguments[0].click();\", calendar_button)\n",
    "    print('clicked calendar button')\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    ## select start date: Jan 1, 2015\n",
    "    # click on the header twice\n",
    "    header_class = \"react-datepicker__header.react-datepicker__header--custom\"\n",
    "    header = wd.find_element(By.CLASS_NAME, header_class)\n",
    "\n",
    "    #header is '< March 2021 >', we want to click on 'March 2021' only, which is the second span.\n",
    "    spans = header.find_elements(By.TAG_NAME, 'span')\n",
    "    wd.execute_script(\"arguments[0].click();\", spans[1])\n",
    "    time.sleep(1)\n",
    "    wd.execute_script(\"arguments[0].click();\", spans[1])\n",
    "    time.sleep(1)\n",
    "\n",
    "    leftClick = wd.find_element(By.CLASS_NAME,'icon-Chevron-left')\n",
    "    wd.execute_script(\"arguments[0].click();\", leftClick)\n",
    "\n",
    "    #select year\n",
    "    year = wd.find_element(By.XPATH, \"//span[text()='2015']\")\n",
    "    wd.execute_script(\"arguments[0].click();\", year) \n",
    "    time.sleep(1)\n",
    "\n",
    "    # #select month\n",
    "    month = wd.find_element(By.XPATH, \"//span[text()='Jan']\")\n",
    "    wd.execute_script(\"arguments[0].click();\", month) \n",
    "    time.sleep(1)\n",
    "\n",
    "    #select day\n",
    "    date_class = \"react-datepicker__day.react-datepicker__day--001\"\n",
    "    date = wd.find_element(By.CLASS_NAME, date_class)\n",
    "    wd.execute_script(\"arguments[0].click();\", date)\n",
    "    time.sleep(1)\n",
    "\n",
    "    # select end date: March 2, 2021\n",
    "    # click on the header again: \n",
    "\n",
    "    header_class = \"react-datepicker__header.react-datepicker__header--custom\"\n",
    "    header = wd.find_element(By.CLASS_NAME, header_class)\n",
    "    spans = header.find_elements(By.TAG_NAME, 'span')\n",
    "    wd.execute_script(\"arguments[0].click();\", spans[1])\n",
    "    time.sleep(1)\n",
    "    wd.execute_script(\"arguments[0].click();\", spans[1])\n",
    "    time.sleep(1)\n",
    "\n",
    "    rightClick = wd.find_element(By.CLASS_NAME,\"icon-Chevron-right\")\n",
    "    wd.execute_script(\"arguments[0].click();\", rightClick)\n",
    "    time.sleep(1)\n",
    "\n",
    "    year2 = wd.find_element(By.XPATH, \"//span[text()='2021']\")\n",
    "    wd.execute_script(\"arguments[0].click();\", year2) \n",
    "    time.sleep(1)\n",
    "\n",
    "    month2 = wd.find_element(By.XPATH, \"//span[text()='Mar']\")\n",
    "    wd.execute_script(\"arguments[0].click();\", month2) \n",
    "    time.sleep(1)\n",
    "\n",
    "    date_class2 = \"react-datepicker__day.react-datepicker__day--002\"\n",
    "    date2 = wd.find_element(By.CLASS_NAME, date_class2)\n",
    "    wd.execute_script(\"arguments[0].click();\", date2)\n",
    "    time.sleep(1)\n",
    "\n",
    "    #click the \"Continue\" button\n",
    "    continue_button = wd.find_element(By.XPATH, \"//button[text()='Continue']\")\n",
    "    wd.execute_script(\"arguments[0].click();\", continue_button)\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    # click the 'Load More\" button for as many times as needed, until it disappears\n",
    "    try:\n",
    "        while True:\n",
    "            WebDriverWait(wd,10).until(EC.presence_of_element_located((By.XPATH,\"//button[text()='Load More']\")))\n",
    "            load_more = wd.find_element(By.XPATH, \"//button[text()='Load More']\")\n",
    "            wd.execute_script(\"arguments[0].click();\", load_more)\n",
    "         \n",
    "    except (TimeoutException):\n",
    "        print(\"loaded all\")\n",
    "\n",
    "\n",
    "    soup = bs(wd.page_source, 'lxml')\n",
    "    tables = soup.find_all('table')\n",
    "\n",
    "    df = pd.read_html(str(tables))[0] #extract entire table\n",
    "    df['url'] = all_url[i]\n",
    "    df.head(5)\n",
    "\n",
    "    if i == 0:\n",
    "        cmc_market = df\n",
    "    else:\n",
    "        cmc_market = cmc_market.append(df, ignore_index=True)\n",
    "\n",
    "    wd.close()\n",
    "\n",
    "cmc_market.to_csv(\"cmc_market_data.csv\")\n",
    "print('saved cmc_market_data.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make all column names lower case, without special characters\n",
    "\n",
    "cmc_market = pd.read_csv(\"cmc_market_data.csv\")\n",
    "\n",
    "cmc_market.rename(columns = {'Date':'date','Close**': 'close', 'Open*': 'open', 'High':'high', 'Low':'low', 'Volume':'volume', 'Market Cap': 'market_cap'}, inplace = True)\n",
    "cmc_market.drop(columns = {'Unnamed: 0'}, inplace = True)\n",
    "\n",
    "# replace values displayed as \"<$0.00000001\" with NaN\n",
    "cmc_market = cmc_market.replace(\"<$0.00000001\",np.nan)\n",
    "\n",
    "#turn market variables into float\n",
    "var1 = ['close', 'volume', 'market_cap']\n",
    "\n",
    "for var in var1:\n",
    "    print(var)\n",
    "    cmc_market[var] = cmc_market[var].str.replace(',', '')\n",
    "    cmc_market[var] = cmc_market[var].str.replace('$', '')\n",
    "    cmc_market[var] = cmc_market[var].astype('float')\n",
    "\n",
    "#change string dates to datetime\n",
    "cmc_market['date'] = cmc_market['date'].str.replace(',', '')\n",
    "cmc_market['date'] = cmc_market['date'].str.replace(' ', '')\n",
    "cmc_market['date'] = pd.to_datetime(cmc_market['date'],format=\"%b%d%Y\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmc_market.to_csv(\"cmc_market_data.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_page = \"https://coinmarketcap.com/cryptocurrency-category/\"\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--incognito')\n",
    "\n",
    "wd = webdriver.Chrome(options=options)\n",
    "wd.get(category_page)\n",
    "soup = bs(wd.page_source, 'lxml')\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "categories = pd.read_html(str(tables))[0] #extract entire table\n",
    "\n",
    "category_url = []\n",
    "rows = soup.find_all(\"tr\")\n",
    "for i in range(1,len(rows)):\n",
    "    links = rows[i].find(\"a\").get(\"href\")\n",
    "    category_url.append(links)\n",
    "\n",
    "categories[\"category_url\"] = category_url\n",
    "categories = categories.drop([\"Top Gainers\", \"Volume\",\"#\"], axis=1)\n",
    "cols = categories.columns.tolist()\n",
    "cols = cols[-1:]+cols[:-1] #reorder so url i smoved from last to first\n",
    "categories = categories[cols]\n",
    "\n",
    "categories.to_csv(\"categories.csv\", index=True)\n",
    "\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   tags (categories)\n",
    "#   contracts (indicate whether there is ethereum contract)\n",
    "\n",
    "\n",
    "cmc_all = pd.read_csv(\"tokens_cmc_2024.csv\")\n",
    "all_url = cmc_all[\"cmc_url\"].tolist()\n",
    "\n",
    "cmc_all['main contract'] = np.nan\n",
    "cmc_all['other contracts'] = np.nan\n",
    "cmc_all['tags_text'] = np.nan\n",
    "\n",
    "showAll_class = 'sc-f70bb44c-0.sc-9ee74f67-1.ixMiII'\n",
    "tag_class = \"sc-f70bb44c-0.sc-9ee74f67-1.dWtIZr\"\n",
    "chain_class = \"chain-name\"\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--incognito')\n",
    "\n",
    "\n",
    "for k in range(1,3):#len(all_url)\n",
    "    \n",
    "    print(k)\n",
    "    url = \"https://coinmarketcap.com\"+all_url[k] \n",
    "    print(url)\n",
    "\n",
    "    wd = webdriver.Chrome(options=options)\n",
    "    wd.get(url)\n",
    "\n",
    "    ## Scrape Contracts\n",
    "    ## Get link to each token's contract on its main chain, \n",
    "    # eg. https://arbiscan.io/token/0x912CE59144191C1204E64559FE8253a0e49E6548 for ARB\n",
    "\n",
    "    try:\n",
    "        WebDriverWait(wd,10).until(EC.presence_of_element_located((By.CLASS_NAME, chain_class)))\n",
    "        main_chain_link = wd.find_element(By.CLASS_NAME, chain_class)\n",
    "        print('found main contract')\n",
    "        link = main_chain_link.get_attribute('href')\n",
    "\n",
    "        #Save the main contract in the cmc_all table for each token\n",
    "        # get row index of the token:\n",
    "        row = cmc_all.index[cmc_all['cmc_url']==all_url[k]][0]\n",
    "        # insert contract for the token:\n",
    "        cmc_all['main contract'][row] = link\n",
    "\n",
    "\n",
    "    except:      \n",
    "        print(\"can't find main contract\")\n",
    "\n",
    "\n",
    "    ## Get links to each token's contracts on the other chains / L2s\n",
    "\n",
    "    # Click the \"More\" button\n",
    "    more_xpath = \"/html/body/div[1]/div[2]/div/div[2]/div/div/div[2]/div[2]/section[2]/div/div[2]/div[1]/div[2]/div/div[2]\"\n",
    "\n",
    "    try:\n",
    "        WebDriverWait(wd,10).until(EC.presence_of_element_located((By.XPATH, more_xpath)))\n",
    "        print('found more button')\n",
    "\n",
    "        more_button = wd.find_element(By.XPATH, more_xpath)\n",
    "        chain = ActionChains(wd)\n",
    "        chain.move_to_element(more_button).perform()\n",
    "\n",
    "        time.sleep(3)\n",
    "\n",
    "        chains_link = wd.find_elements(By.CLASS_NAME, chain_class)\n",
    "        more_links = [i.get_attribute('href') for i in chains_link]\n",
    "\n",
    "        #Save the other contracts in the cmc_all table for each token\n",
    "        # get row index of the token:\n",
    "        row = cmc_all.index[cmc_all['cmc_url']==all_url[k]][0]\n",
    "        # insert contract for the token:\n",
    "        cmc_all['other contracts'][row] = more_links\n",
    "\n",
    "    except:      \n",
    "        print(\"can't find more button\")\n",
    "\n",
    "    ## Scrape Tags\n",
    "    try:\n",
    "    # If the Show all button is available, click on it and scrape all the tags\n",
    "\n",
    "        WebDriverWait(wd,10).until(EC.presence_of_element_located((By.CLASS_NAME, showAll_class)))\n",
    "        print('found Show all button')\n",
    "\n",
    "        showAll_button = wd.find_element(By.CLASS_NAME, showAll_class)\n",
    "        wd.execute_script(\"arguments[0].click();\", showAll_button)\n",
    "        time.sleep(1)\n",
    "\n",
    "        tag_link = wd.find_elements(By.CLASS_NAME, tag_class)\n",
    "        tags_text = [i.text for i in tag_link]\n",
    "\n",
    "        #Save tags in the cmc_all table for each token\n",
    "        # get row index of the token:\n",
    "        row = cmc_all.index[cmc_all['cmc_url']==all_url[k]][0]\n",
    "        # insert tags for the token:\n",
    "        cmc_all['tags_text'][row] = tags_text\n",
    "\n",
    "    except:      \n",
    "        print(\"can't find Show all button\")\n",
    "        # If Show all button is unavailable, just scrape the tags shown\n",
    "        try:\n",
    "            WebDriverWait(wd,10).until(EC.presence_of_element_located((By.CLASS_NAME, tag_class)))\n",
    "            print('found Tags')\n",
    "            tag_link = wd.find_elements(By.CLASS_NAME, tag_class)\n",
    "            tags_text = [i.text for i in tag_link]\n",
    "\n",
    "            #Save tags in the cmc_all table for each token\n",
    "            # get row index of the token:\n",
    "            row = cmc_all.index[cmc_all['cmc_url']==all_url[k]][0]\n",
    "            # insert tags for the token:\n",
    "            cmc_all['tags_text'][row] = tags_text\n",
    "        except:\n",
    "            print('No tags')\n",
    "\n",
    "\n",
    "    wd.close()\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://coinmarketcap.com/currencies/sperax/\"\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--incognito')\n",
    "\n",
    "wd = webdriver.Chrome(options=options)\n",
    "wd.get(url)\n",
    "\n",
    "cmc_all['tags_link'] = np.nan\n",
    "cmc_all['tags_text'] = np.nan\n",
    "\n",
    "\n",
    "showAll_class = 'sc-f70bb44c-0.sc-9ee74f67-1.ixMiII'\n",
    "tag_class = \"sc-f70bb44c-0.sc-9ee74f67-1.dWtIZr\"\n",
    "\n",
    "\n",
    "try:\n",
    "    # If the Show all button is available, click on it and scrape all the tags\n",
    "\n",
    "    WebDriverWait(wd,10).until(EC.presence_of_element_located((By.CLASS_NAME, showAll_class)))\n",
    "    print('found Show all button')\n",
    "\n",
    "    showAll_button = wd.find_element(By.CLASS_NAME, showAll_class)\n",
    "    wd.execute_script(\"arguments[0].click();\", showAll_button)\n",
    "    time.sleep(1)\n",
    "\n",
    "    tag_link = wd.find_elements(By.CLASS_NAME, tag_class)\n",
    "    tags_text = [i.text for i in tag_link]\n",
    "\n",
    "    #Save tags in the cmc_all table for each token\n",
    "    # get row index of the token:\n",
    "    row = cmc_all.index[cmc_all['cmc_url']==all_url[k]][0]\n",
    "    # insert tags for the token:\n",
    "    cmc_all['tags_text'][row] = tags_text\n",
    "\n",
    "except:      \n",
    "    print(\"can't find Show all button\")\n",
    "    # If Show all button is unavailable, just scrape the tags shown\n",
    "    try:\n",
    "        WebDriverWait(wd,10).until(EC.presence_of_element_located((By.CLASS_NAME, tag_class)))\n",
    "        print('found Tags')\n",
    "        tag_link = wd.find_elements(By.CLASS_NAME, tag_class)\n",
    "        tags_text = [i.text for i in tag_link]\n",
    "\n",
    "        #Save tags in the cmc_all table for each token\n",
    "        # get row index of the token:\n",
    "        row = cmc_all.index[cmc_all['cmc_url']==all_url[k]][0]\n",
    "        # insert tags for the token:\n",
    "        cmc_all['tags_text'][row] = tags_text\n",
    "    except:\n",
    "        print('No tags')\n",
    "\n",
    "#<span class=\"sc-f70bb44c-0 sc-9ee74f67-1 dWtIZr\"><a href=\"/view/scaling/\" class=\"cmc-link\">Scaling</a></span>\n",
    "\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#drop tokens without instrinsic value: ie pegged to something else. \n",
    "cmc_all = pd.read_csv(\"cmc_all_tags1.csv\") # should I be using cmc_all_tags.csv instead?\n",
    "indexnames = cmc_all[(cmc_all['Stablecoin']==1) | (cmc_all[\"Synthetics\"]==1)|(cmc_all[\"Tokenized Stock\"]==1 )\n",
    "                   | (cmc_all['Wrapped Tokens']==1) | (cmc_all['ETH 2.0 Staking']==1)\n",
    "                   | (cmc_all['ETH 2.0 Staking']==1)].index\n",
    "cmc_all.drop(indexnames,inplace=True)\n",
    "\n",
    "#defi combines: DeFi, Yield Farming, AMM, Oracles, Lending/borrowing, derivatives, yield aggregator, insurance, rebase, seigniorage, options, Defi index,DEX, yearn partnership\n",
    "cmc_all['defi'] = np.where((cmc_all[\"DeFi\"]==1 )|(cmc_all[\"Yield farming\"]==1) |(cmc_all[\"AMM\"]==1)|(cmc_all[\"Lending / Borrowing\"]==1)\n",
    "                |(cmc_all[\"Derivatives\"]==1)|(cmc_all[\"Yield Aggregator\"]==1)|(cmc_all[\"Insurance\"]==1)\n",
    "                | (cmc_all[\"Rebase\"]==1) |(cmc_all[\"Seigniorage\"]==1) |(cmc_all[\"Options\"]==1)\n",
    "                | (cmc_all[\"DeFi Index\"]==1) | (cmc_all[\"Decentralized exchange\"]==1) | (cmc_all[\"Yearn Partnerships\"]==1),1, np.nan)\n",
    "\n",
    "# distributed_comp combines: Filesharing, storage, distributed computing\n",
    "cmc_all[\"distributed_comp\"] = np.where((cmc_all[\"Filesharing\"]==1 )|(cmc_all[\"Storage\"]==1 )|(cmc_all[\"Distributed Computing\"]==1),1,np.nan)\n",
    "\n",
    "#entertainment combines: Content Creation, Media, Memes, Videos, entertainment, music, fan token, \n",
    "#                       communication and social media, events, social money, gaming, sports, gambling\n",
    "cmc_all[\"entertainment\"] = np.where((cmc_all[\"Content Creation\"]==1)|(cmc_all[\"Media\"]==1)|(cmc_all[\"Memes\"]==1)|\n",
    "                        (cmc_all[\"Video\"]==1)|(cmc_all[\"Entertainment\"]==1)| (cmc_all[\"Music\"]==1)|\n",
    "                        (cmc_all[\"Fan token\"]==1)|(cmc_all[\"Communications & Social Media\"]==1)|(cmc_all[\"Events\"]==1)\n",
    "                        |(cmc_all[\"Social Money\"]==1)|(cmc_all[\"Gaming\"]==1)|(cmc_all[\"Sports\"]==1)|(cmc_all[\"Gambling\"]==1)|(cmc_all[\"NFTs & Collectibles\"]==1),1,np.nan)\n",
    "\n",
    "#infrastructure combines scaling, interoperability, smart contract platform\n",
    "cmc_all[\"infrastructure\"] = np.where((cmc_all[\"Scaling\"]==1)|(cmc_all[\"Interoperability\"]==1)|(cmc_all[\"Smart Contracts\"]==1),1,np.nan)\n",
    "\n",
    "cmc_all = cmc_all.rename(columns = {\"Centralized exchange\": \"cex\", \"Privacy\":\"privacy\",\"Asset management\":\"asset_management\"})\n",
    "cmc_all[\"biz_solution\"] = np.where((cmc_all[\"Identity\"]==1)|(cmc_all[\"Analytics\"]==1)|(cmc_all[\"Marketing\"]==1)|\n",
    "                            (cmc_all[\"Logistics\"]==1),1,np.nan)\n",
    "\n",
    "#drop categories that have been combined together. \n",
    "cmc_all = cmc_all.drop([\"DeFi\",\"Yield farming\",\"AMM\",\"Lending / Borrowing\",\"Derivatives\",\"Yield Aggregator\"\n",
    "                        ,\"Insurance\",\"Rebase\",\"Seigniorage\",\"Options\",\"DeFi Index\",\"Decentralized exchange\"\n",
    "                        ,\"Yearn Partnerships\",\"Content Creation\",\"Media\",\"Memes\",\"Video\",\"Entertainment\",\"Music\"\n",
    "                        ,\"Fan token\",\"Communications & Social Media\",\"Events\",\"Social Money\",\"Gaming\",\"Sports\"\n",
    "                        ,\"Gambling\",\"NFTs & Collectibles\",\"Scaling\",\"Interoperability\",\"Smart Contracts\",\"Identity\"\n",
    "                        ,\"Analytics\",\"Marketing\",\"Logistics\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmc_all.to_csv(\"cmc_industry_groups.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmc_contract = pd.read_csv(\"cmc_contract_all.csv\")\n",
    "industries = pd.read_csv(\"cmc_industry_groups.csv\")\n",
    "cmc_market = pd.read_csv(\"cmc_market_all.csv\")\n",
    "cmc_market = cmc_market.rename(columns = {\"url\":\"cmc_url\"})\n",
    "contract_industries = cmc_contract.merge(industries, how=\"outer\", on=[\"cmc_url\"])\n",
    "market_data = contract_industries.merge(cmc_market,how=\"outer\",on=[\"cmc_url\"])\n",
    "market_data.to_csv(\"market_data.csv\",index=False)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}